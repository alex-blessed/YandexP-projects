{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Привет Александр! Меня зовут Марат, и я буду твоим ревьюером. Спешу сообщить что все ключевые этапы в работе выполнены,  с задачей тебе удалось справиться. По поводу обращения - в IT сфере принято общаться на «ты» :) Но, если привычней на «вы», дай знать. Как ревьюера моя задача помочь тебе в развитии, дав хорошие советы. Я внимательно посмотрю твой код, ознакомлюсь с твоими выводами и оставлю комментарии. Где то могу предложить небольшие исправление в коде, но ненавязчиво. Где потребуются уточнения, я оставлю много наводящих вопросов. Они помогут тебя с поиском верного решения.\n",
    "\n",
    "Все мои комментарии размечены по цветам, для лучшего восприятия. \n",
    "    \n",
    "<div class=\"alert alert-success\">Зеленым цветом и словом «Успех» отмечены особо удачные и элегантные решения, которыми ты можешь гордиться. </div>\n",
    "        \n",
    "<div class=\"alert alert-warning\">Желтым и значком словом «Совет», помечены решения у которых есть альтернативные решения, более оптимальные. Ты можешь найти их сразу и доработать проект, или отложить это на потом, для будущих проектах. Проект будет принят и без их доработки. </div>\n",
    "        \n",
    "<div class=\"alert alert-danger\"> Красным цветом и значком словом «Ошибка» помечу твои решения, на которые стоит обратить внимание прежде всего. После их доработки проект будет принят. </div>\n",
    "        \n",
    "Залог успеха - работа сообща, взаимное уважение и работа в диалоге. Поэтому, помечай свои ответные комментарии на мои реплики заметным цветом или курсивом, так мне будет легче их отслеживать. Пожалуйста, не изменяй и не удаляй мои комментарии. Все это поможет выполнить повторную проверку быстрей.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендация тарифов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оператор мобильной связи «Мегалайн» выяснил: многие клиенты пользуются архивными тарифами. Они хотят построить систему, способную проанализировать поведение клиентов и предложить пользователям новый тариф: «Смарт» или «Ультра».\n",
    "\n",
    "**Цель исследования**\n",
    "  \n",
    "Создать систему рекомендаций тарифов на основе данных о использовании мобильной сети и мобильного трафика пользователями\n",
    "\n",
    "**Ход исследования**\n",
    "\n",
    " - Сформируем обучающую, валидационную и тестовую выборки\n",
    " - Изучим точность нескольких моделей: `дерева решений`, `случайного леса` и `логистической регрессии`\n",
    " - Проверим наиболее точную модель на тестовой выборке\n",
    " - проверим наиболее точную модель в тесте на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "Вступление в работу очень важно, так человек, который смотрит твой проект (и на работе в том числе) будет сразу введен в курс дела.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Откройте и изучите файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "Собираем все импорты в верхней части, чтобы легче было ориентироваться и добавлять новые по необходимости. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Совет:     \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "- кстати есть рекомендации PEP-8 при написании кода, в том числе и для импортов. Если интересно можешь почитать [тут](https://pythonworld.ru/osnovy/pep-8-rukovodstvo-po-napisaniyu-koda-na-python.html), в будущем пригодится )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'users_behavior.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_242/1075671766.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'users_behavior.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'users_behavior.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('users_behavior.csv')\n",
    "df.info()\n",
    "df.head()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "    \n",
    "Мне пришлось подправить твой код чтобы запустилось. Для некоторых особо строгих ревьюеров это основание завернуть работу без проверки, так что будь внимательней в следующий раз )\n",
    "    \n",
    "Совет - используй конструкцию try except:    \n",
    "  \n",
    "    try:\n",
    "\n",
    "        df = pd.read_csv('C:/your_project/users_behavior.csv')\n",
    "    except:\n",
    "\n",
    "        df = pd.read_csv('/datasets/users_behavior.csv')\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "👍 Данные изучены.\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Можно еще отдельно проверить датасет на сбалансированность классов в таргете. Это помогло бы решить бонусное задание сразу (Только не надо балансировать данные, это тема следующего проекта).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Можно посмотреть корреляцию признаков. Знаешь что такое мультиколлинеарность, какие два типа проблем возникает, для каких моделей и какие варианты решения?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбейте данные на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем данные на три части - для обучения, валидации и теста в соотношении 60%:20%:20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['is_ultra'], axis=1)\n",
    "target = df['is_ultra']\n",
    "\n",
    "features_train, features_valid_test, target_train, target_valid_test = train_test_split(\n",
    "    features, target, test_size=0.4, random_state=123)\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_valid_test, target_valid_test, test_size=0.5, random_state=321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "Все правильно!\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "- Обрати внимание на аргумент stratify, он позволит сохранить изначальное распределение таргетов во всех новых датасетах.  Существующий дисбаланс никуда не денется, но в каждом датасете он будет одинаковым. [Почитать](https://pythonru.com/baza-znanij/sklearn-train-test-split) можно тут\n",
    "\n",
    "\n",
    "- После разбиения лучше перестраховаться и использовать .shape, для контроля за корректностью разбиения\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследуйте модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая модель для исследования - дерево решений. Попробуем глубину дерева от 1 до 20 и выберем самую удачную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(return_model=False):\n",
    "    accuracy_train = []\n",
    "    accuracy_valid = []\n",
    "    best_accuracy = 0\n",
    "    best_depth = 0\n",
    "\n",
    "    for depth in range(1, 20):\n",
    "        model = DecisionTreeClassifier(max_depth=depth, random_state=123)\n",
    "        model.fit(features_train, target_train)\n",
    "\n",
    "        answers_train = model.predict(features_train)\n",
    "        answers_valid = model.predict(features_valid)\n",
    "\n",
    "        accuracy_train.append(accuracy_score(target_train, answers_train))\n",
    "        accuracy_valid.append(accuracy_score(target_valid, answers_valid))\n",
    "\n",
    "        if accuracy_valid[depth - 1] > best_accuracy:\n",
    "            best_accuracy = accuracy_valid[depth - 1]\n",
    "            best_depth = depth\n",
    "            best_model = model\n",
    "\n",
    "    sns.set()\n",
    "    xaxis = range(1, len(accuracy_train)+1)\n",
    "    sns.lineplot(x=xaxis, y=accuracy_train, label='train')\n",
    "    sns.lineplot(x=xaxis, y=accuracy_valid, label='valid')\n",
    "    plt.xlabel('Глубина дерева')\n",
    "    plt.ylabel('Точность')\n",
    "    plt.show()\n",
    "    print('Оптимальная глубина:', best_depth)\n",
    "    print('Лучшая точность:', best_accuracy)\n",
    "\n",
    "decision_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что модель начинает переобучаться, если задать слишком высокий гиперпараметр глубины"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    " \n",
    "Работа выполнена в соответствии с критериями: \n",
    "\n",
    "\n",
    "\n",
    " - модель обучена на обучающем наборе\n",
    " - получена оценка качества на валидационном наборе\n",
    " - перебор гиперпараметров осуществляется в цикле\n",
    "\n",
    "\n",
    "Отличный график, и верный вывод\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "- tree_plot можно построить, с max_depth равной 3 или 4 (глубже уже будет громоздко) - глянуть как DT сплиты делает, будет понимание как модель принимает решения: какие признаки  использует, на каких значениях делает разбиение вправо - влево \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лес деревьев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующая модель - лес деревьев. Его обучение и перебор количества деревьев займет больше времени, но и точность ожидается выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest():\n",
    "    accuracy_train = []\n",
    "    accuracy_valid = []\n",
    "    best_accuracy = 0\n",
    "    best_est = 0\n",
    "\n",
    "    for est in range(1, 100):\n",
    "        model = RandomForestClassifier(n_estimators=est, random_state=123)\n",
    "        model.fit(features_train, target_train)\n",
    "\n",
    "        answers_train = model.predict(features_train)\n",
    "        answers_valid = model.predict(features_valid)\n",
    "\n",
    "        accuracy_train.append(accuracy_score(target_train, answers_train))\n",
    "        accuracy_valid.append(accuracy_score(target_valid, answers_valid))\n",
    "\n",
    "        if accuracy_valid[est - 1] > best_accuracy:\n",
    "            best_accuracy = accuracy_valid[est - 1]\n",
    "            best_est = est\n",
    "\n",
    "    sns.set()\n",
    "    xaxis = range(1, len(accuracy_train)+1)\n",
    "    sns.lineplot(x=xaxis, y=accuracy_train, label='train')\n",
    "    sns.lineplot(x=xaxis, y=accuracy_valid, label='valid')\n",
    "    plt.xlabel('Количество деревьев')\n",
    "    plt.ylabel('Точность')\n",
    "    plt.show()\n",
    "    print('Оптимальное количество деревьев:', best_est)\n",
    "    print('Лучшая точность:', best_accuracy)\n",
    "\n",
    "random_forest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Узнали, что нет смысла \"растить\" больше 39 деревьев в одном лесу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Совет 🤔:\n",
    "\n",
    "\n",
    "\n",
    "- Александр, можно было сделать похитрее, RF одна из лучших моделей в классическом machine-learning, поэтому можно было добавить перебор 2 гиперпараметров в двойном цикле, в результата метрика качества вырастет. \n",
    " \n",
    "\n",
    "\n",
    "- Когда что то долго крутиться, можно использовать  %%time - ставишь на самый вверх ячейки с кодом, время выполнения которого хочешь замерить, может не знаешь.  Быстрее не станет, но все будут видеть стоит ли ждать не отходя от ПК или можно сходить чаек поставить )) \n",
    "    \n",
    "    Или tqdm, это ещё лучше, потому что он показывает интерактивно, на каком этапе расчетов мы находимся\n",
    "\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "\n",
    "\n",
    "    for n_estimators in tqdm(range(3,58)):\n",
    "\n",
    "        ..........\n",
    "\n",
    "\n",
    "\n",
    "(дальше мы будем уходить от неэффективных в питоне циклов к apply.  Там тоже есть аналог прогресс-баров:  .progress_apply)\n",
    "    \n",
    "И будет красиво )   \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "- Видишь разницу, и можешь объяснить разницу между поведением метрики на валидации у дерева решений и случайного леса \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель - логистическая регрессия. У нее попробуем поменять гиперпараметр итераций обучения от 100 до 1000 с шагом в 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression():\n",
    "    accuracy_train = []\n",
    "    accuracy_valid = []\n",
    "    best_accuracy = 0\n",
    "    best_iter = 0\n",
    "\n",
    "    for iterations in range(100, 1001, 100):\n",
    "        model = LogisticRegression(max_iter=iterations, random_state=123)\n",
    "        model.fit(features_train, target_train)\n",
    "\n",
    "        answers_train = model.predict(features_train)\n",
    "        answers_valid = model.predict(features_valid)\n",
    "\n",
    "        accuracy_train.append(accuracy_score(target_train, answers_train))\n",
    "        accuracy_valid.append(accuracy_score(target_valid, answers_valid))\n",
    "\n",
    "        if accuracy_valid[iterations//100 - 1] > best_accuracy:\n",
    "            best_accuracy = accuracy_valid[iterations//100 - 1]\n",
    "            best_iter = iterations\n",
    "\n",
    "    sns.set()\n",
    "    xaxis = range(100, len(accuracy_train)*100+1, 100)\n",
    "    sns.lineplot(x=xaxis, y=accuracy_train, label='train')\n",
    "    sns.lineplot(x=xaxis, y=accuracy_valid, label='valid')\n",
    "    plt.xlabel('Количество итераций обучения')\n",
    "    plt.ylabel('Точность')\n",
    "    plt.show()\n",
    "    print('Оптимальное количество итераций обучения:', best_iter)\n",
    "    print('Лучшая точность:', best_accuracy)\n",
    "\n",
    "logistic_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гиперпараметр никак не повлиял на точность обученной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итог\n",
    "---\n",
    "По итогам, наиболее точной в предсказаниях оказалась модель случайного леса. Ее мы дальше и проверим на тестовой выборке, а также на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "Все верно, RF лучший. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "Если есть желание можешь ответить на вопросики ))    \n",
    "\n",
    "\n",
    "\n",
    "- Как назвать ситуацию, когда на валидации при увеличении глубины дерева (модель DT), метрика качества стала снижаться? Как по твоему в это же время вела себя эта же метрика на train?\n",
    "\n",
    "\n",
    "- Насколько знаю вы еще под капот моделям не заглядывали, но может знаешь почему обычно RF показывает более высокие результаты из выбранных?\n",
    "\n",
    "\n",
    "- Мы решаем задачу классификации (а еще есть задача регрессии), а в названии модели с помощью которой мы решаем задачу \"классификации\" (Логистическая регрессия) есть слово \"регрессия\".  Нет ли тут парадокса? )\n",
    "    \n",
    "\n",
    "- Почему логистическая регрессия показывать на много более худшие результаты?  \n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверьте модель на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RandomForestClassifier(n_estimators=39, random_state=123)\n",
    "best_model.fit(features_train, target_train)\n",
    "answers_test = best_model.predict(features_test)\n",
    "print('Точность на тестовой выборке', accuracy_score(target_test, answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность оказалась на уровне валидирующей выборки, что ожидаемо"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "- Все верно, логика моделирования не нарушена, тут тестируем только лучшую модель (или парочку, если метрики были близки) отобранную на валидации. \n",
    "\n",
    "- Если студент получил на тесте accuraсy  выше 0,78, это считается отличным результатом. Ты подбираешь лучшую комбинацию не по одному гиперпараметру и вот он результат!\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Вопросики и совет:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Как попробовать улучшить результат, не мучаясь с кодом?! Смотри - мы сформировали train выборку на которой обучаем модель, а валидационную используем для поиска лучших значений гиперпараметров. Оке, нашли их. Так почему бы теперь модель с выбранными гиперпараметрами не обучить на тренировочной + валидационной выборке (только не нужно делать новые сплиты, используй pd.concat(), к примеру)?! Чем больше данных, тем лучше модель может обучиться. И эту дообученную модель проверим на тесте. Гаранитий что станет лучше нет, но ML это постоянные эксперименты.  \n",
    "    \n",
    "    \n",
    "- А можешь предложить как нам использовать полученный результат в бизнесе? Как нам на этих прогнозах сделать деньги? \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Александр, в качестве бонуса можешь вывести еще несколько метрик своей модели - precision, recall, F1 и confussion matrix) Все есть в sklearn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (бонус) Проверьте модели на адекватность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_classifier = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_classifier.fit(features_train, target_train)\n",
    "dummyclassifier_answers = dummy_classifier.predict(features_test)\n",
    "print('Точность случайной модели', accuracy_score(target_test, dummyclassifier_answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность модели, которая всегда будет отвечать 0 или 1(тот ответ, которого в обучающей выборке большинство) составляет 0.69, а у нашей 0.81. Это значит, наша модель пусть немного, но все же умнее случайной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "Все верно. \n",
    "\n",
    "👍 что используешь специальную обертку для проверки на адекватность\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итог\n",
    "\n",
    "При создании системы рекомендаций протестировали три типа модели:\n",
    "- Дерево решений\n",
    "- Случайный лес\n",
    "- Логистическая регрессия\n",
    "\n",
    "Самой точной оказалась `модель Случайного леса` - с точностью 0.81, которая также усппешно прошла проверку на адекватность.\n",
    "\n",
    "При изменении случайного распределения и обучения(random_state) могут незначительно меняться оптимальные гиперпараметры для моделей, а также точность. Но модель случайного леса всегда остается самой точной и проходит тест на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Александр, у тебя старательно выполненная работа, все четко, осмысленно. Выводы присутствуют\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "Я оставил небольшие советы и вопросики (если есть время и желание можешь воспользоваться/ответить): \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- обрати внимание на проверку сбалансированность классов в таргете в разделе EDA\n",
    "- использовать stratify\n",
    "- добавить график метрики    \n",
    "- как можно улучшить результаты \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "Обязательное к исправлению:\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "- ошибка неисполнения кода\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "Жду исправлений, для принятия проекта. Если какие то вопросы, то сразу спрашивай ) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист готовности проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставьте 'x' в выполненных пунктах. Далее нажмите Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Jupyter Notebook открыт\n",
    "- [x] Весь код исполняется без ошибок\n",
    "- [x] Ячейки с кодом расположены в порядке исполнения\n",
    "- [x] Выполнено задание 1: данные загружены и изучены\n",
    "- [x] Выполнено задание 2: данные разбиты на три выборки\n",
    "- [x] Выполнено задание 3: проведено исследование моделей\n",
    "    - [x] Рассмотрено больше одной модели\n",
    "    - [x] Рассмотрено хотя бы 3 значения гипепараметров для какой-нибудь модели\n",
    "    - [x] Написаны выводы по результатам исследования\n",
    "- [x] Выполнено задание 3: Проведено тестирование\n",
    "- [x] Удалось достичь accuracy не меньше 0.75\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
