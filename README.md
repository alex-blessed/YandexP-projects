# Машинное обучение для текстов
## Обучение модели классификации комментариев

**Стек:** spacy / scikit-learn / numpy / pandas / python

**Описание проекта**: Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других.

**Задача:** Создать модель классификации комментариев на позитивные и негативные.
Метрика качества - F1. Она должна быть не ниже 0.75.

**План реализации проекта:**
 * Импорт данных
 * Перевод текста в признак
   * Очистка текста
   * Лемматизация текста
   * Расчет TF-IDF
 * Обучение моделей
 * Тестирование финальной модели

## Ход работы

## Перевод текста в признак  

Использовали библиотеку spacy с таким пайплайном:
 * Токенизатор - разделяет предложения в блоке текста на части, токены
 * POS тэггер - каждому слову присвает часть речи (сам POS tag)
 * Лемматизатор - приводит слово к его лемме

А также очистили текст (небуквенные символы, единый регистр, единичные буквы)
И перевели текст в признаки с помощью TfidfVectorizer  
> TF-IDF (от англ. term frequency и inverse document frequency — частота слова и обратная частота документа) — это показатель, который используется для оценки важности слова в документе.  
TF (частота слов) характеризует отношение числа вхождений конкретного слова к общему набору слов в документе. Чем выше TF, тем весомее конкретное слово в рамках документа.
## Обучение моделей

Обучили 3 модели - LogisticRegression, LinearSVC, ComplementNB  
Лучший результат на кросс-валидаци (3 фолда) показала модель **LinearSVC** (**F1=0.77**)
## Вывод 

Для задачи классификации комментариев на негативные и позитивные были обучены и протестированы несколько моделей.
Обучались модели на размеченных комментариях, переведенных в матрицу векторов TF-IDF(оценки важности слова в контексте документа).

Наилучший результат на тестовой выборке показала модель **LinearSVC с F1 = 0.78** (требуемый результат >0.75)