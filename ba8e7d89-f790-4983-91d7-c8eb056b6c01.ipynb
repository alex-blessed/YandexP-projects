{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Привет Александр! Меня зовут Марат, и я буду твоим ревьюером. Спешу сообщить что все ключевые этапы в работе выполнены,  с задачей тебе удалось справиться. По поводу обращения - в IT сфере принято общаться на «ты» :) Но, если привычней на «вы», дай знать. Как ревьюера моя задача помочь тебе в развитии, дав хорошие советы. Я внимательно посмотрю твой код, ознакомлюсь с твоими выводами и оставлю комментарии. Где то могу предложить небольшие исправление в коде, но ненавязчиво. Где потребуются уточнения, я оставлю много наводящих вопросов. Они помогут тебя с поиском верного решения.\n",
    "\n",
    "Все мои комментарии размечены по цветам, для лучшего восприятия. \n",
    "    \n",
    "<div class=\"alert alert-success\">Зеленым цветом и словом «Успех» отмечены особо удачные и элегантные решения, которыми ты можешь гордиться. </div>\n",
    "        \n",
    "<div class=\"alert alert-warning\">Желтым и значком словом «Совет», помечены решения у которых есть альтернативные решения, более оптимальные. Ты можешь найти их сразу и доработать проект, или отложить это на потом, для будущих проектах. Проект будет принят и без их доработки. </div>\n",
    "        \n",
    "<div class=\"alert alert-danger\"> Красным цветом и значком словом «Ошибка» помечу твои решения, на которые стоит обратить внимание прежде всего. После их доработки проект будет принят. </div>\n",
    "        \n",
    "Залог успеха - работа сообща, взаимное уважение и работа в диалоге. Поэтому, помечай свои ответные комментарии на мои реплики заметным цветом или курсивом, так мне будет легче их отслеживать. Пожалуйста, не изменяй и не удаляй мои комментарии. Все это поможет выполнить повторную проверку быстрей.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других.  \n",
    "\n",
    "**Цель работы:**  \n",
    "Создать модель классификации комментариев на позитивные и негативные.  \n",
    "Метрика качества - *F1*. Она должна быть не ниже 0.75.  \n",
    "\n",
    "**Ход работы**\n",
    "1. Импорт данных\n",
    "2. Перевод текста в признак\n",
    "    - Очистка текста\n",
    "    - Лемматизация текста\n",
    "    - Расчет TF-IDF\n",
    "3. Обучение моделей \n",
    "4. Тестирование финальной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, GridSearchCV)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data_raw = pd.read_csv('toxic_comments.csv')\n",
    "except:\n",
    "    data_raw = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "Если не знаешь - чтобы не было столбца  `Unnamed: 0` при чтении файла можно так:\n",
    "\n",
    "\n",
    "    pd.read_csv(..., index_col=0)\n",
    "\n",
    "    \n",
    "(`Unnamed: 0` появляется при не совсем корректном сохранении файла)    \n",
    "\n",
    "\n",
    "Unnamed: 0 это \"след\" старых индексов. Если ты уберёшь первые 10 примеров и своего датасета, сохранишь его, а потом откроешь,  то появится столбец Unnamed: 0 начиная с цифры 9, и появится новый индексы начиная с нуля \n",
    "\n",
    "\n",
    "Но это мелочь,  даже не нужно ничего исправлять. Просто знай, чтобы увидев такое в чужом коде не удивляться что бы это могло означать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153124</th>\n",
       "      <td>153281</td>\n",
       "      <td>In other words, the meat puppets are acting li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137781</th>\n",
       "      <td>137928</td>\n",
       "      <td>\"\\n\\n A beating \\n\\nHello Shovon, I see you've...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153246</th>\n",
       "      <td>153403</td>\n",
       "      <td>You racked up more than four in the dreamcast....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102014</th>\n",
       "      <td>102111</td>\n",
       "      <td>\":Do you mean \"\"where can I find a list of Hob...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100130</th>\n",
       "      <td>100227</td>\n",
       "      <td>framing and which sources giving</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "153124      153281  In other words, the meat puppets are acting li...      0\n",
       "137781      137928  \"\\n\\n A beating \\n\\nHello Shovon, I see you've...      1\n",
       "153246      153403  You racked up more than four in the dreamcast....      0\n",
       "102014      102111  \":Do you mean \"\"where can I find a list of Hob...      0\n",
       "100130      100227                   framing and which sources giving      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберем лишний столбец *Unnamed: 0*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = data_raw.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "Данные изучены. Небольшой EDA не помешает, так как это аналитический проект. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- стоило еще проверить на сбалансированность классов в таргете это важная информация при моделировании и  корректной оценки модели. и к нему график можно, ведь красивый, хорошо оформленный график может быть украшением проекта. \n",
    "\n",
    "\n",
    "    \n",
    "- .sample() вместо .head(), ведь если данные каким то образом упорядоченны, то шансы увидеть что то разнообразное через .sample чуть выше чем через .head (или .tail)     \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Готовим признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачаем из библиотеки nltk нужные нам вещи(лемматизатор и стоп-слова)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функцию, которая:\n",
    " - Убирает из текса небуквенные символы, единичные буквы\n",
    " - Приводит каждое слово к его лемме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_lem(text):\n",
    "    lower = text.lower()\n",
    "    clear = re.sub('[^a-z]', ' ', lower)\n",
    "    cleared = re.sub(r'\\b\\w{1,2}\\b', ' ', clear).split()\n",
    "    sentence = ' '.join(cleared)\n",
    "    doc = nlp(sentence)\n",
    "    tokens = [tokens for tokens in doc if (tokens.is_stop == False)]\n",
    "    tokens = [tokens for tokens in tokens if (tokens.is_punct == False)]\n",
    "    final_token = [token.lemma_ for token in tokens]\n",
    "    res = ' '.join(final_token)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "－－－－－－－－－－－\n",
      "Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "⬇️⬇️⬇️⬇️⬇️⬇️\n",
      "\n",
      "explanation edit username hardcore metallica fan revert weren vandalism closure gas vote new york dolls fac don remove template talk page retire\n",
      "－－－－－－－－－－－\n",
      "D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\n",
      "⬇️⬇️⬇️⬇️⬇️⬇️\n",
      "\n",
      "aww match background colour seemingly stuck thank talk january utc\n",
      "－－－－－－－－－－－\n",
      "Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\n",
      "⬇️⬇️⬇️⬇️⬇️⬇️\n",
      "\n",
      "hey man try edit war guy constantly remove relevant information talk edit instead talk page care formatting actual info\n"
     ]
    }
   ],
   "source": [
    "data = data_raw[0:3].copy()\n",
    "data['text'] = data['text'].apply(clean_and_lem)\n",
    "\n",
    "for i in range(3):\n",
    "    print('－－－－－－－－－－－')\n",
    "    print(data_raw['text'][i])\n",
    "    print('⬇️⬇️⬇️⬇️⬇️⬇️', end='\\n\\n')\n",
    "    print(data['text'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "\n",
    "\n",
    "- WordNetLemmatizer  рабочий вариант, но у него есть особенности, для корректной работы ему нужно передавать не просто слово, но и POS-тег (Part of Speech, части речи). Набираемся ума-разума [тут](https://webdevblog.ru/podhody-lemmatizacii-s-primerami-v-python/) )  Обрати внимание на функцию `get_wordnet_pos`. Сразу хочу предупредить, что если делать Лемматизацию правильно, сучетом постегов, то время может занять полчаса-час. Так что не удивляйся (вообще советую сохранить результаты Лематизации в каком-то файлике, чтобы каждый раз не тратить на это много времени)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- лемматизацию можно было сделать с помощью SpaCy лемматизатором и прямо скажем как инструмент он более удобен и универсален, не нужно заморачиваться с токенизацией и учётом пос тегов\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Чтобы сэкономить время, и убедиться что всё отработало нормально, берёшь парочку предложений, создаёшь dataframe\n",
    "    \n",
    "    \n",
    "    sentence1 = \"The striped bats are hanging on their feet for best\"\n",
    "    sentence2 = \"you should be ashamed of yourself went worked\"\n",
    "    df_my = pd.DataFrame([sentence1, sentence2], columns = ['text'])\n",
    "    print(df_my)\n",
    "\n",
    "\n",
    "    print(df_my['text'].apply(func))\n",
    "    \n",
    "    \n",
    "    \n",
    "И тестируешь не нем, должно получиться \n",
    "    \n",
    "    \n",
    "    \n",
    "    striped  ------> strip, went -------> go  \n",
    "\n",
    "\n",
    "\n",
    "Если всё получилось, то можно использовать на всём датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a99dd4306943f0b75893617d0e3490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=19912), Label(value='0 / 19912')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pandarallel.initialize(progress_bar=True)\n",
    "data = data_raw.copy()\n",
    "data['text'] = data['text'].parallel_apply(clean_and_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('lemmatized', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "\n",
    "- Плюс за использование apply, неэффективные циклы нам ни к чему.\n",
    "\n",
    "\n",
    "- Да, всегда лучше проверить что получилось  в итоге, так всегда будет возможность поправить ошибку\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "    \n",
    "- попробуй .progress_apply, делает что .apply, но еще и показывает на какой итерации находится процесс.  \n",
    "\n",
    "Для некоторых версий, чтобы заработал .progress_apply предварительно нужно сделать:\n",
    "    \n",
    "    \n",
    "    from tqdm.notebook import tqdm\n",
    "    tqdm.pandas()\n",
    "    \n",
    "\n",
    "И cудя по всему импорты нужно засунуть внутрь функции\n",
    "\n",
    "То же самое делает .swifter.apply  Предварительно\n",
    "\n",
    "\n",
    "    !pip install swifter\n",
    "    import swifter\n",
    "\n",
    "\n",
    "\n",
    "- если  процесс лемматизации затягивается, можно попробовать [.parallel_apply](https://pypi.org/project/pandarallel/),  кому-то это помогает уменьшить время прогона кода раз в 5-7 (Хотя студенты начинают жаловаться что получается даже медленнее). А у большинства он вообще не запускается ) Предварительно: \n",
    "\n",
    "    \n",
    "    from pandarallel import pandarallel   \n",
    "    tqdm.pandas(desc=\"progress\")\n",
    "    pandarallel.initialize(progress_bar = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- после очистки и лемматизации (и убрав стопслова) можно провести частотный анализ текста/[облако слов](https://habr.com/ru/post/517410/) - чтобы получить общее представление о тематике и о наиболее часто встречаемых словах в токсичных и нетоксичных твитах Кроме того графики, рисунки делают проект визуально интересней\n",
    "    \n",
    "В тренажере облако импортируем так\n",
    "\n",
    "    !/opt/conda/bin/python -m pip install wordcloud \n",
    "\n",
    "\n",
    "или\n",
    "\n",
    "    !/opt/conda/bin/python -m pip install wordcloud==1.8.2.2  \n",
    "\n",
    "\n",
    "И возможно дополнительно надо будет сделать\n",
    "\n",
    "\n",
    "\n",
    "    !pip install --upgrade Pillow\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "- когда что то долго крутиться, можно использовать  %%time - ставишь на самый вверх ячейки с кодом, время выполнения которого хочешь замерить, может не знаешь.  Быстрее не станет, но все будут видеть стоит ли ждать не отходя от ПК или можно сходить чаек поставить ))  \n",
    "\n",
    "\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Делим на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим на train/test выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127433, 2) (31859, 2)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(\n",
    "    data, test_size=0.2, stratify=data['toxic'], random_state=123)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "\n",
    "- random_state не забываем поставить, иначе каждый новый запуск новый сплит, и новые результаты моделирования\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И разделим признаки и таргет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['text']\n",
    "X_test = test['text']\n",
    "\n",
    "y_train = train['toxic']\n",
    "y_test = test['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "Не забыли о стопсловах, они ни к чему и код побежит быстрей\n",
    "\n",
    "    \n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет:     \n",
    "\n",
    "Вопросик:\n",
    "\n",
    "А стопслова важней убирать  когда мы используем TF-IDF, или когда используе обычный CountVectorizer? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Совет:\n",
    "\n",
    "\n",
    "- .fit_transform на train датасете, .transform на test/valid. Вроде все верно, но после ты подаешь tf_idf_train в GridSearchCV или cross_val_score и он внутри себя разбивая его на тренировочный и валидационный датасет, получается подглядывание в будущее (утечка данных). Решение в использовании pipeline, ниже распишу\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После TfidfVectorizer мы получили признаки в виде разреженной матрицы(sparse matrix).  \n",
    "Поэтому, возьмем модели, которые умеют с такой матрицей работать.  \n",
    "Точность моделей будем проверять кросс-валидацией(5 фолдов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат f1: 0.773\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=13, max_iter=1000, random_state=123)\n",
    "pipe = make_pipeline(vectorizer, model)\n",
    "cv = cross_val_score(pipe, X_train, y_train, cv=3, scoring='f1', n_jobs=4)\n",
    "print('Результат f1: {:.3f}'.format(cv.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {'logisticregression__C':np.logspace(-2, 2, 10)}\n",
    "gs = GridSearchCV(pipe, parameters, scoring='f1', cv=3, n_jobs=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "\n",
    "Не забываем при инициализации модели о random_state, иначе после каждого запуска кода у нас может быть разный результат\n",
    "\n",
    "\n",
    "И интересно откуда ты взял C=10.  Значение отличные от дефолтных мы находим, а не просто вставляя откуда-то\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат f1: 0.777\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(random_state=123)\n",
    "pipe = make_pipeline(vectorizer, model)\n",
    "cv = cross_val_score(pipe, X_train, y_train, cv=3, scoring='f1', n_jobs=4)\n",
    "print('Результат f1: {:.3f}'.format(cv.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {'linearsvc__C':np.logspace(-1, 1, 10)}\n",
    "gs = GridSearchCV(pipe, parameters, scoring='f1', cv=3, n_jobs=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат f1: 0.671\n"
     ]
    }
   ],
   "source": [
    "model = ComplementNB(alpha=0.2)\n",
    "pipe = make_pipeline(vectorizer, model)\n",
    "cv = cross_val_score(pipe, X_train, y_train, cv=3, scoring='f1', n_jobs=4)\n",
    "print('Результат f1: {:.3f}'.format(cv.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {'complementnb__alpha':np.logspace(-2, 1, 10)}\n",
    "gs = GridSearchCV(pipe, parameters, scoring='f1', cv=3, n_jobs=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Ошибка:    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "Всё-таки стоит поперебирать гиперпараметры\n",
    "    \n",
    "Есть два варианта исправить красное:\n",
    "    \n",
    "    \n",
    "1. Подобрать лучшие гиперпараметры в вручную написанном цикле \n",
    "    \n",
    "    \n",
    "2.  Можно вместо цикла использовать sklearn-ий встроенный функционал GridSearch. В случаи использования GridSearch, не нужно будет заранее делать валидационную выборку, лучшую метрику автоматом сохранят в best_score_, а лучшую модель (переобученная уже на полном наборе данных) будет хранить в best_estimator_, данные обучения положит в cv_restult_. А главное  он сделает несколько разбиений на train / validation выборки (кросс-валидация), тем самым поборется с рандомом, когда на валидации получен хороший результат только изза удачного сплита. \n",
    "\n",
    "А еще лучше использовать связку GridSearchCV + pipeline. \n",
    "\n",
    "[Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), это тема которая сразу затрагивает кроссвалидацию, тюнинг \"векторайз\", подбор гиперпараметров модели и о том что код стоит делать компактным.\n",
    "    \n",
    "    \n",
    "- в TfidfVectorizer(stop_words=stopwords) у тебя по умолчанию ngram_range=(1, 1), тут можно подбирать разное число n- грамм (и другие параметры), максимизируя метрику, но как объединить перебор по ngram_range с обучением моделей, чтобы не делать это по отдельности или с использованием цикла?! pipeline! Готовый [пример для работы с текстами](https://medium.com/@yoni.levine/how-to-grid-search-with-a-pipeline-93147835d916). Всё что нужно там есть, хотя очень лаконично. Можешь погуглить по:\n",
    "\n",
    "\n",
    "    \n",
    "    pipeline nlp gridsearchcv\n",
    "    \n",
    "    \n",
    "- как избежать ошибки подглядывания в будущее, когда мы предварительно работаем с данными (шкалирование, нормализация, TfidfVectorizer итп итд)? pipeline! особенно это важно, когда мы используем кроссвалидацию. Для TfidfVectorizer делаеь .fit (обучаемся) на train, а transform на test, точно также нужно сделать для валидационной выборки. Но GS делает валидационные внутри себя, спрашивается как добраться до них и избежать подглядывания в будущее? Казалось бы никак, но нет! Pipeline! ) \n",
    "    \n",
    "    \n",
    "- pipeline позволяет делать наш код компактней и читабельней, это большой плюс, когда код будет раздуваться   \n",
    "\n",
    "\n",
    "\n",
    "В общем если сделать GS+pieline будет вообще хорошо )  \n",
    "    \n",
    "    \n",
    "    \n",
    "и только затем, выбрав лучшую модель (с лучшими значениями гиперпараметров) проведем тестирование на датасете о котором наша модель не имеет никакого представления. И если окажется что тестовая метрика (нашей лучшей на валидации модели) не удовлетворяет критериям качества, то мы начнем процесс моделирования с начала (а не будем пробовать другие модели которые были хуже на валидации - по приниципу \"а вдруг другая модель подойдет\").    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "По итогам лучший результат на тренировочной выборке показала модель LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Узнаем результат на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат f1: 0.786\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(random_state=123)\n",
    "pipe = make_pipeline(vectorizer, model)\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print('Результат f1: {:.3f}'.format(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех: \n",
    "\n",
    "- Все верно, логика моделирования не нарушена, тут тестируем только лучшую модель отобранную на валидации, или парочку лучших, если на валидации результаты близки\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Если студент получил на тесте f1 выше 0,75, это считается приемлемым результатом.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "Что может помочь добиться лучшего результата (от простого)? \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- можно поиграться [порогом](https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/). Таким образом можно поднять метрику на процент - полтора\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "- подобрать лучшие гиперпараметры с использованием кроссвалидации (тут пригодится GridSearchCV) \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    " - полезно настраивать векторайзеры  (тут пригодится pipeline). Это конечно потребует вычислительных мощностей, ведь если даже использовать биграммы число признаков резко увеличится\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "- сгенерировать новые фичи, например  например посчитать число слов в тексте, длину слов итп итд. Или с помощью [тематического моделирования](https://pythobyte.com/python-for-nlp-topic-modeling-8fb3d689/) \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- использование предбученной модели Берта, выбрав соответствующую модель и используя полученные эмбединги, даже на небольшом тренировочном датасете можно обучить модель, которая на test покажет хорошую метрику. В этом случаи можно сразу получить метрику > 0.95 (при правильно выбранной модели)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "А ещё можешь посмотреть какие слова  является наиболее важным для классификации с точки зрения модели. Получаем список слов    \n",
    "    \n",
    "    \n",
    "    \n",
    "    .get_feature_names_out().tolist()\n",
    "    \n",
    "    \n",
    "    \n",
    "Получаем коэффициенты важности (для логистическая регрессии)    \n",
    "    \n",
    "    .coef_.tolist()[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задачи классификации комментариев на негативные и позитивные были обучены и протестированы несколько моделей.  \n",
    "Обучались модели на размеченных комментариях, переведенных в матрицу векторов *TF-IDF*(оценки важности слова в контексте документа).  \n",
    "\n",
    "Наилучший результат на тестовой выборке показала модель **LinearSVC** с **F1 = 0.77** (требуемый результат >0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Александр, у тебя старательно выполненная работа, все четко, осмысленно. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Логика моделирования не нарушена\n",
    "    \n",
    "    \n",
    "Я оставил небольшие советы и вопросики (если есть время и желание можешь воспользоваться/ответить).\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "Обязательное к исправлению:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- WordNetLemmatizer используем с POS - тег \n",
    "\n",
    "\n",
    "- при инициализации модели и сплите не забываем random_state (можно один раз вначале просто прописать random.seed(42), чтобы не прописывать каждый раз везде random_state. Кстати знаешь откуда 42?)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- нет перебора гиперпараметров (это можно сделать с помощью вручную прописанных циклов либо с помощью GridSearchCV)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Жду исправлений, для принятия проекта. Если какие то вопросы, то сразу спрашивай ) \n",
    "\n",
    "\n",
    "<font color='green'><b>Полезные (и просто интересные) материалы:</b> \\\n",
    "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множествореализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "\n",
    "\n",
    "Если понравилась работа с текстами, то можешь посмотреть очень интересный (но очень-очень сложный) курс лекций: https://github.com/yandexdataschool/nlp_course .\n",
    "\n",
    "Если нравится смотреть и слушать то есть целый курс на Ютубе https://www.youtube.com/watch?v=qDMwIQRQt-M&list=PLEwK9wdS5g0qksxWxtE5c2KuFkIfUXe3i&index=1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
